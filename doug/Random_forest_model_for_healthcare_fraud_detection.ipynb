{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model for Healthcare Fraud Detection\n",
    "### Deborah Leong, Sam Nuzbrokh and Doug Devens\n",
    "\n",
    "This notedbook describes development of a random forest classification model to detect potentially fraudulent healthcare providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas package and scikitlearn metrics reports.  Read in file created by provider_inout_mods.  Also read in the mean residual by provider created by notebook 'Provider_claim_data_regression' and is described elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Provider', 'MeanResidualReimbursement', 'logOPAnnualReimbursement',\n",
       "       'logIPAnnualReimbursement', '$PerClaimDay', 'InscClaimAmtReimbursed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "x_train_inout_mod = pd.read_csv('x_train_inout_mod.csv')\n",
    "provider_reimb_residuals=pd.read_csv('provider_groups_residual.csv')\n",
    "provider_reimb_residuals =provider_reimb_residuals.drop(columns=['Unnamed: 0'])\n",
    "provider_reimb_residuals.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns in provider_reimb_residuals and drop extra column brought in with file read-in.  Merge the two files on provider to combine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_reimb_residuals.columns=['Provider','MeanResidualReimbursement','logOPAnnualReimbursement',\\\n",
    "                'logIPAnnualReimbursement','$PerClaimDay','total_claim']\n",
    "x_train_inout_mod = x_train_inout_mod.drop(columns = 'Unnamed: 0')\n",
    "x_train_inout_mod = pd.merge(x_train_inout_mod,provider_reimb_residuals,on='Provider')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also bring in data from the market basket analysis, which found a higher fraction of diabetes and ischemic heart patients for fraudulent providers.  We include that as a feature in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Provider', 'PctDiabFrac'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_frac = pd.read_csv('diabetes_frac.csv')\n",
    "diabetes_frac.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_frac = diabetes_frac.drop(columns = ['Unnamed: 0'])\n",
    "x_train_inout_mod = pd.merge(x_train_inout_mod,diabetes_frac, on='Provider')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm all columns are numeric, except 'Provider;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Provider'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train_inout_mod.select_dtypes(exclude='number').columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move 'PotentialFraud\" label data to target array.  Drop from features matrix in next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age_in', 'Age_out', 'AttendingPhysician_in', 'AttendingPhysician_out',\n",
       "       'ClaimDays_in', 'ClaimDays_out', 'DeductibleAmtPaid_in',\n",
       "       'DeductibleAmtPaid_out', 'Gender_in', 'Gender_out',\n",
       "       'InscClaimAmtReimbursed_in', 'InscClaimAmtReimbursed_out',\n",
       "       'NumChronics_in', 'NumChronics_out', 'NumDiag_in', 'NumDiag_out',\n",
       "       'NumProc_in', 'NumProc_out', 'State_in', 'State_out', 'WhetherDead_in',\n",
       "       'WhetherDead_out', 'ClaimDays_in_Range', 'ClaimDays_out_Range',\n",
       "       'InscClaimAmtReimbursed_in_Range', 'InscClaimAmtReimbursed_out_Range',\n",
       "       'NumChronics_in_Range', 'NumChronics_out_Range', 'NumDiag_in_Range',\n",
       "       'NumDiag_out_Range', 'NumProc_in_Range', 'NumProc_out_Range',\n",
       "       'Provider', 'PotentialFraud', 'docDegMax', 'docBtwnMean', 'docEignMean',\n",
       "       'docMANN', 'patDegMax', 'patBtwnMean', 'patEignMean', 'patMANN',\n",
       "       'ClmsPerPhysician_in', 'ClmsPerPhysician_out', 'ClmsPerPatient_in',\n",
       "       'ClmsPerPatient_out', 'DrPerPatient_in', 'DrPerPatient_out',\n",
       "       'LogPatients_in', 'LogPatients_out', 'LogClaims_in', 'LogClaims_out',\n",
       "       'LogOpPhys_in', 'LogOpPhys_out', 'LogOtherPhys_in', 'LogOtherPhys_out',\n",
       "       'AgeRange_otpt', 'cardiology_otpt', 'urology_otpt',\n",
       "       'endocrinology_otpt', 'emergency_otpt', 'general_otpt',\n",
       "       'infectious_otpt', 'oncology_otpt', 'hematology_otpt',\n",
       "       'psychiatry_otpt', 'neurology_otpt', 'pulmonology_otpt',\n",
       "       'gastroenterology_otpt', 'ob-gyn_otpt', 'dermatology_otpt',\n",
       "       'orthopedics_otpt', 'congenital_otpt', 'neonatology_otpt',\n",
       "       'AgeRange_inpt', 'cardiology_inpt', 'urology_inpt',\n",
       "       'endocrinology_inpt', 'emergency_inpt', 'general_inpt',\n",
       "       'infectious_inpt', 'oncology_inpt', 'hematology_inpt',\n",
       "       'psychiatry_inpt', 'neurology_inpt', 'pulmonology_inpt',\n",
       "       'gastroenterology_inpt', 'ob-gyn_inpt', 'dermatology_inpt',\n",
       "       'orthopedics_inpt', 'congenital_inpt', 'neonatology_inpt',\n",
       "       'MeanResidualReimbursement', 'logOPAnnualReimbursement',\n",
       "       'logIPAnnualReimbursement', '$PerClaimDay', 'total_claim',\n",
       "       'PctDiabFrac'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_inout_mod.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the target or response array and confirm here that we have the same number of fraudulent providers across the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4904\n",
       "1     506\n",
       "Name: PotentialFraud, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x_train_inout_mod['PotentialFraud']\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the 'PotentialFraud' column since it is the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train_inout_mod.drop(columns = ['PotentialFraud'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import test_train_split from sklearn and split matrices into training and test sets for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, \n",
    "                                            test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create provider_claim matrices to be able to merge later to perform cost calculations.  Scale train and test columns from original X matrix.  Model will be scaled from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4328, 95)\n",
      "(1082, 95)\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(columns=['Provider','total_claim'])\n",
    "\n",
    "provider_claim_trn=X_train[['Provider','total_claim']]\n",
    "X_train=X_train.drop(columns=['Provider','total_claim'])\n",
    "X_train=(X_train-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "print(X_train.shape)\n",
    "\n",
    "provider_claim_test=X_test[['Provider','total_claim']]\n",
    "X_test=X_test.drop(columns=['Provider','total_claim'])\n",
    "X_test=(X_test-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm there are no more NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=X_test.fillna(0)\n",
    "c = np.sum(X_test.isnull())\n",
    "c[c>0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ensamble model and create instance of random forest model.  Run first instance.  Previous trials with weighting that running with class_weight equal to balanced and then slightly underweighting with the sample_weight option in the fit gave better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[916  61]\n",
      " [ 24  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       977\n",
      "           1       0.57      0.77      0.66       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.77      0.85      0.81      1082\n",
      "weighted avg       0.94      0.92      0.93      1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rfparams_dict = {}\n",
    "from sklearn import ensemble\n",
    "randomForest = ensemble.RandomForestClassifier()\n",
    "randomForest.set_params(class_weight = 'balanced',random_state=42, n_estimators=110, max_features=15, \\\n",
    "            min_samples_leaf = 12, min_samples_split=3,criterion='gini',oob_score=True)\n",
    "sample_weight = np.array([1 if x==0 else 0.9 for x in y_train])\n",
    "randomForest.fit(X_train, y_train,sample_weight=sample_weight) # fit \n",
    "print(confusion_matrix(y_test, randomForest.predict(X_test)))\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features=15,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=12, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=110,\n",
       "                       n_jobs=None, oob_score=True, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a cross-validation grid search to optimize parameter settings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[916  61]\n",
      " [ 27  78]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rfminfeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfminfeatures' is not defined"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_para_forest = [{\n",
    "    \"n_estimators\": range(80,151,25),\n",
    "    \"criterion\": [\"gini\",'entropy'],\n",
    "    \"min_samples_leaf\": range(12,31,5),\n",
    "    \"min_samples_split\": range(2,9,2),\n",
    "    \"random_state\": [42],\n",
    "    'max_features':range(8,21,4)}]\n",
    "grid_search_forest = GridSearchCV(randomForest, grid_para_forest, scoring='f1_weighted', cv=5, n_jobs=3)\n",
    "grid_search_forest.fit(X_train, y_train)\n",
    "bst_prm = grid_search_forest.best_params_\n",
    "randomForest.set_params(class_weight = 'balanced',min_samples_split=bst_prm['min_samples_split'],random_state=42, \n",
    "                        n_estimators=bst_prm['n_estimators'], max_features=bst_prm['max_features'], \\\n",
    "                        criterion = bst_prm['criterion'], min_samples_leaf = bst_prm['min_samples_leaf'])\n",
    "randomForest.fit(X_train, y_train,sample_weight=None)\n",
    "print(confusion_matrix(y_test, randomForest.predict(X_test)))\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the set of best parameters and compare their performance against the prior 'naive' model.  We see the F1 score has dropped slightly.  We also see the model parameter selection has tended more toward overfitting with the smallest number of samples per leaf and samples per split chosen.  We notice the grid search chose entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 20, 'min_samples_leaf': 12, 'min_samples_split': 2, 'n_estimators': 130, 'random_state': 42}\n",
      "[[916  61]\n",
      " [ 27  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       977\n",
      "           1       0.56      0.74      0.64       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.77      0.84      0.80      1082\n",
      "weighted avg       0.93      0.92      0.92      1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bst_prm)\n",
    "print(confusion_matrix(y_test, randomForest.predict(X_test)))\n",
    "print(classification_report(y_test, randomForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to stay with the original parameters (e.g. 'gini' loss function, instead of entropy) and other selections.  We know that the performance of the random forest is also dependent on the random number generator.  To introduce a measure of noise into the model training we fit the model for various values of the random state, and then save the F1 score, the confusion matrix, and a dataframe of labeled feature importances for each iteration, to allow a more representative view of feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[912  65]\n",
      " [ 25  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       977\n",
      "           1       0.55      0.76      0.64       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.76      0.85      0.80      1082\n",
      "weighted avg       0.93      0.92      0.92      1082\n",
      "\n",
      "[[913  64]\n",
      " [ 26  79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       977\n",
      "           1       0.55      0.75      0.64       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.76      0.84      0.80      1082\n",
      "weighted avg       0.93      0.92      0.92      1082\n",
      "\n",
      "[[916  61]\n",
      " [ 24  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       977\n",
      "           1       0.57      0.77      0.66       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.77      0.85      0.81      1082\n",
      "weighted avg       0.94      0.92      0.93      1082\n",
      "\n",
      "[[915  62]\n",
      " [ 24  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       977\n",
      "           1       0.57      0.77      0.65       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.77      0.85      0.80      1082\n",
      "weighted avg       0.93      0.92      0.93      1082\n",
      "\n",
      "[[917  60]\n",
      " [ 27  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       977\n",
      "           1       0.57      0.74      0.64       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.77      0.84      0.80      1082\n",
      "weighted avg       0.93      0.92      0.92      1082\n",
      "\n",
      "[[915  62]\n",
      " [ 27  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       977\n",
      "           1       0.56      0.74      0.64       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.76      0.84      0.80      1082\n",
      "weighted avg       0.93      0.92      0.92      1082\n",
      "\n",
      "[[912  65]\n",
      " [ 27  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       977\n",
      "           1       0.55      0.74      0.63       105\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.76      0.84      0.79      1082\n",
      "weighted avg       0.93      0.91      0.92      1082\n",
      "\n",
      "[[912  65]\n",
      " [ 25  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       977\n",
      "           1       0.55      0.76      0.64       105\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.76      0.85      0.80      1082\n",
      "weighted avg       0.93      0.92      0.92      1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.array([1 if x==0 else 0.9 for x in y_train])\n",
    "rndm_score_dict = {}\n",
    "for i in range(8):\n",
    "    rnint = np.random.randint(0,1000000)\n",
    "    randomForest.set_params(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
    "           criterion='gini', max_depth=None, max_features=15,\n",
    "           max_leaf_nodes=None, max_samples=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=12, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=110,\n",
    "           n_jobs=None, oob_score=True, random_state=rnint, verbose=0,\n",
    "           warm_start=False)\n",
    "    randomForest.fit(X_train, y_train,sample_weight=sample_weight)\n",
    "    print(confusion_matrix(y_test, randomForest.predict(X_test)))\n",
    "    print(classification_report(y_test, randomForest.predict(X_test)))\n",
    "    rndm_score_dict[rnint]=[confusion_matrix(y_test, randomForest.predict(X_test)),\\\n",
    "    ''.join([classification_report(y_test, randomForest.predict(X_test))[x] for x in range(148,152)]),\\\n",
    "    pd.DataFrame(list(zip(X_train.columns, randomForest.feature_importances_))).sort_values(by = 1, ascending=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate a composite confusion matrix (easier for me to read) to understand the true range of likely performance in classification. We see an average F1 score of 0.64, and identification of 80 of the 105 fraudulent providers in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " median, std F1 score for fraud  (0.64, 0.008291561975888507)\n",
      "      true neg                   false pos\n",
      "(914.0, 1.8708286933869707) (63.0, 1.8708286933869707)\n",
      "      false neg                   true pos\n",
      "(25.5, 1.2183492931011204) (79.5, 1.2183492931011204)\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "med_true_neg = statistics.median([rndm_score_dict[x][0][0][0] for x in rndm_score_dict.keys()])\n",
    "std_true_neg = np.std([rndm_score_dict[x][0][0][0] for x in rndm_score_dict.keys()])\n",
    "med_false_pos = statistics.median([rndm_score_dict[x][0][0][1] for x in rndm_score_dict.keys()])\n",
    "std_false_pos = np.std([rndm_score_dict[x][0][0][1] for x in rndm_score_dict.keys()])\n",
    "med_false_neg = statistics.median([rndm_score_dict[x][0][1][0] for x in rndm_score_dict.keys()])\n",
    "std_false_neg = np.std([rndm_score_dict[x][0][1][0] for x in rndm_score_dict.keys()])\n",
    "med_true_pos = statistics.median([rndm_score_dict[x][0][1][1] for x in rndm_score_dict.keys()])\n",
    "std_true_pos = np.std([rndm_score_dict[x][0][1][1] for x in rndm_score_dict.keys()])\n",
    "med_f1 = statistics.median([float(rndm_score_dict[x][1]) for x in rndm_score_dict.keys()])\n",
    "std_f1 = np.std([float(rndm_score_dict[x][1]) for x in rndm_score_dict.keys()])\n",
    "# print(med_f1)\n",
    "print(' median, std F1 score for fraud ',(med_f1,std_f1))\n",
    "print('      true neg                   false pos')\n",
    "print((med_true_neg,std_true_neg),(med_false_pos,std_false_pos))\n",
    "print('      false neg                   true pos')\n",
    "print((med_false_neg,std_false_neg),(med_true_pos,std_true_pos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the average feature importance across all the random number iterations, from the feature importance dataframes created in each iteration.  We then view the bottom 20 (lowest feature importance) features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>RF_Feature_Imp_Ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>general_otpt</td>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>LogOtherPhys_out</td>\n",
       "      <td>0.001795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>docBtwnMean</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>docEignMean</td>\n",
       "      <td>0.001709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>AttendingPhysician_in</td>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>LogOpPhys_in</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Gender_in</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>docDegMax</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>LogOtherPhys_in</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>congenital_inpt</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ob-gyn_inpt</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>NumProc_out_Range</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>State_in</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ClaimDays_out_Range</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NumProc_out</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>WhetherDead_in</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>DeductibleAmtPaid_in</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ClmsPerPhysician_in</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ClmsPerPhysician_out</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>neonatology_inpt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0  RF_Feature_Imp_Ave\n",
       "72           general_otpt            0.001819\n",
       "69       LogOtherPhys_out            0.001795\n",
       "68            docBtwnMean            0.001770\n",
       "77            docEignMean            0.001709\n",
       "66  AttendingPhysician_in            0.001642\n",
       "80           LogOpPhys_in            0.001587\n",
       "70              Gender_in            0.001537\n",
       "82              docDegMax            0.000753\n",
       "84        LogOtherPhys_in            0.000584\n",
       "85        congenital_inpt            0.000562\n",
       "83            ob-gyn_inpt            0.000509\n",
       "86      NumProc_out_Range            0.000492\n",
       "87               State_in            0.000318\n",
       "88    ClaimDays_out_Range            0.000301\n",
       "94            NumProc_out            0.000133\n",
       "89         WhetherDead_in            0.000069\n",
       "92   DeductibleAmtPaid_in            0.000034\n",
       "90    ClmsPerPhysician_in            0.000000\n",
       "91   ClmsPerPhysician_out            0.000000\n",
       "93       neonatology_inpt            0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Feature_Imp_Ave = rndm_score_dict[187403][2][[0]]\n",
    "for key in rndm_score_dict.keys():\n",
    "    RF_Feature_Imp_Ave = pd.merge(RF_Feature_Imp_Ave,rndm_score_dict[key][2], on=0)\n",
    "RF_Feature_Imp_Ave['RF_Feature_Imp_Ave']=RF_Feature_Imp_Ave.mean(axis=1)\n",
    "RF_Feature_Imp_Ave = RF_Feature_Imp_Ave.sort_values(by='RF_Feature_Imp_Ave', ascending=False)\n",
    "RF_Feature_Imp_Ave = RF_Feature_Imp_Ave.drop(columns=['1_x','1_y','1_x','1_y','1_y','1_y'])\n",
    "RF_Feature_Imp_Ave.tail(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did use the RFECV (reduced feature engine, cross-validate) but found in several instances that it would remove features that had been quite important in the feature importance tables created in the prior step.  For that reason we removed this step and reduced the features by simply removing the bottom 25 features with the lowest average feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sample_weight = np.array([1 if x==0 else 0.9 for x in y_train])\n",
    "# randomForest.set_params(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
    "#            criterion='gini', max_depth=None, max_features=15,\n",
    "#            max_leaf_nodes=None, max_samples=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=12, min_samples_split=3,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=110,\n",
    "#            n_jobs=None, oob_score=True, random_state=rnint, verbose=0,\n",
    "#            warm_start=False)\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# rfecv = RFECV(randomForest, step=1, min_features_to_select=15, cv=3, scoring='f1_weighted', verbose=0, \\\n",
    "#               n_jobs=3)\n",
    "# rfecv = rfecv.fit(X_train, y_train)\n",
    "# a = [X_train.columns[i] for i in range(len(X_train.columns)) if rfecv.support_[i]]\n",
    "# rfminfeatures = rfecv.estimator_\n",
    "# lilx_train = X_train[a]\n",
    "# rfminfeatures.fit(lilx_train, y_train)\n",
    "# lilx_test= X_test[a]\n",
    "# print('   0    1    predicted is columns')\n",
    "# print(confusion_matrix(y_test, rfminfeatures.predict(lilx_test)))\n",
    "# print(classification_report(y_test, rfminfeatures.predict(lilx_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Feature_Imp_Ave.to_csv('rf_feature_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we identify the features (bottom 25 by average feature importance) to be removed from the reduced feature model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClaimDays_out',\n",
       " 'pulmonology_otpt',\n",
       " 'urology_inpt',\n",
       " 'LogOpPhys_out',\n",
       " 'AttendingPhysician_out',\n",
       " 'general_otpt',\n",
       " 'LogOtherPhys_out',\n",
       " 'docBtwnMean',\n",
       " 'docEignMean',\n",
       " 'AttendingPhysician_in',\n",
       " 'LogOpPhys_in',\n",
       " 'Gender_in',\n",
       " 'docDegMax',\n",
       " 'LogOtherPhys_in',\n",
       " 'congenital_inpt',\n",
       " 'ob-gyn_inpt',\n",
       " 'NumProc_out_Range',\n",
       " 'State_in',\n",
       " 'ClaimDays_out_Range',\n",
       " 'NumProc_out',\n",
       " 'WhetherDead_in',\n",
       " 'DeductibleAmtPaid_in',\n",
       " 'ClmsPerPhysician_in',\n",
       " 'ClmsPerPhysician_out',\n",
       " 'neonatology_inpt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = RF_Feature_Imp_Ave.tail(25)\n",
    "drop_list = list(a[0])\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the bottom 25 features and then iterate across multiple random numbers to generate an average F1 score, average confusion matrix and average feature importance for the reduced model. We see the average F1 score for the reduced feature model remains unchanged, as does the average confusion matrix performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for reduced random forest on test set, minus bottom 25 features\n",
      "70\n",
      " median, std F1 score for fraud  (0.645, 0.006959705453537534)\n",
      "      true neg                   false pos\n",
      "(911.5, 1.118033988749895) (65.5, 1.118033988749895)\n",
      "      false neg                   true pos\n",
      "(24.0, 1.0532687216470449) (81.0, 1.0532687216470449)\n",
      "metrics for train set with reduced features\n",
      "[[3723  204]\n",
      " [  17  384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      3927\n",
      "           1       0.65      0.96      0.78       401\n",
      "\n",
      "    accuracy                           0.95      4328\n",
      "   macro avg       0.82      0.95      0.87      4328\n",
      "weighted avg       0.96      0.95      0.95      4328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_reduced = X_train.drop(columns=drop_list)\n",
    "X_test_reduced = X_test.drop(columns=drop_list)\n",
    "sample_weight = np.array([1 if x==0 else 0.9 for x in y_train])\n",
    "rndm_score_red_dict = {}\n",
    "for i in range(8):\n",
    "    rnint = np.random.randint(0,1000000)\n",
    "    randomForest.set_params(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
    "           criterion='gini', max_depth=None, max_features=15,\n",
    "           max_leaf_nodes=None, max_samples=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=12, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=110,\n",
    "           n_jobs=None, oob_score=True, random_state=rnint, verbose=0,\n",
    "           warm_start=False)\n",
    "    randomForest.fit(X_train_reduced, y_train,sample_weight=sample_weight)\n",
    "#     print(confusion_matrix(y_test, randomForest.predict(X_test_reduced)))\n",
    "#     print(classification_report(y_test, randomForest.predict(X_test_reduced)))\n",
    "    rndm_score_red_dict[rnint]=[confusion_matrix(y_test, randomForest.predict(X_test_reduced)),\\\n",
    "    ''.join([classification_report(y_test, randomForest.predict(X_test_reduced))[x] for x in range(148,152)]),\\\n",
    "    pd.DataFrame(list(zip(X_train_reduced.columns, randomForest.feature_importances_))).sort_values(by = 1, ascending=False)]\n",
    "    \n",
    "med_true_neg = statistics.median([rndm_score_red_dict[x][0][0][0] for x in rndm_score_red_dict.keys()])\n",
    "std_true_neg = np.std([rndm_score_red_dict[x][0][0][0] for x in rndm_score_red_dict.keys()])\n",
    "med_false_pos = statistics.median([rndm_score_red_dict[x][0][0][1] for x in rndm_score_red_dict.keys()])\n",
    "std_false_pos = np.std([rndm_score_red_dict[x][0][0][1] for x in rndm_score_red_dict.keys()])\n",
    "med_false_neg = statistics.median([rndm_score_red_dict[x][0][1][0] for x in rndm_score_red_dict.keys()])\n",
    "std_false_neg = np.std([rndm_score_red_dict[x][0][1][0] for x in rndm_score_red_dict.keys()])\n",
    "med_true_pos = statistics.median([rndm_score_red_dict[x][0][1][1] for x in rndm_score_red_dict.keys()])\n",
    "std_true_pos = np.std([rndm_score_red_dict[x][0][1][1] for x in rndm_score_red_dict.keys()])\n",
    "med_f1 = statistics.median([float(rndm_score_red_dict[x][1]) for x in rndm_score_red_dict.keys()])\n",
    "std_f1 = np.std([float(rndm_score_red_dict[x][1]) for x in rndm_score_red_dict.keys()])\n",
    "# print(med_f1)\n",
    "print('Metrics for reduced random forest on test set, minus bottom 25 features')\n",
    "print(len(X_train_reduced.columns))\n",
    "print(' median, std F1 score for fraud ',(med_f1,std_f1))\n",
    "print('      true neg                   false pos')\n",
    "print((med_true_neg,std_true_neg),(med_false_pos,std_false_pos))\n",
    "print('      false neg                   true pos')\n",
    "print((med_false_neg,std_false_neg),(med_true_pos,std_true_pos))\n",
    "print('metrics for train set with reduced features')\n",
    "print(confusion_matrix(y_train, randomForest.predict(X_train_reduced)))\n",
    "print(classification_report(y_train, randomForest.predict(X_train_reduced)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the average feature importance across all the random iterations, and find the Range of Claim Durations, the number of claims, the range of reimbursements and the number of patients are the most important features in this model. These are roughly in accordance with the other tree-based models we've examined, including gradient boost, adaboost and logit boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>RF_Feature_Imp_Ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClaimDays_in_Range</td>\n",
       "      <td>0.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogClaims_in</td>\n",
       "      <td>0.095395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InscClaimAmtReimbursed_in_Range</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogPatients_in</td>\n",
       "      <td>0.071365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogClaims_out</td>\n",
       "      <td>0.056503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ClaimDays_in</td>\n",
       "      <td>0.039349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogPatients_out</td>\n",
       "      <td>0.035343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NumProc_in_Range</td>\n",
       "      <td>0.033260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ClmsPerPatient_in</td>\n",
       "      <td>0.029042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumDiag_in_Range</td>\n",
       "      <td>0.022861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AgeRange_inpt</td>\n",
       "      <td>0.022254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PctDiabFrac</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AgeRange_otpt</td>\n",
       "      <td>0.018941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>InscClaimAmtReimbursed_out_Range</td>\n",
       "      <td>0.016910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InscClaimAmtReimbursed_in</td>\n",
       "      <td>0.016868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NumChronics_in_Range</td>\n",
       "      <td>0.015928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ClmsPerPatient_out</td>\n",
       "      <td>0.015854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>patDegMax</td>\n",
       "      <td>0.011160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oncology_inpt</td>\n",
       "      <td>0.009314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>emergency_inpt</td>\n",
       "      <td>0.008924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0  RF_Feature_Imp_Ave\n",
       "0                 ClaimDays_in_Range            0.204300\n",
       "1                       LogClaims_in            0.095395\n",
       "2    InscClaimAmtReimbursed_in_Range            0.079452\n",
       "3                     LogPatients_in            0.071365\n",
       "4                      LogClaims_out            0.056503\n",
       "7                       ClaimDays_in            0.039349\n",
       "6                    LogPatients_out            0.035343\n",
       "5                   NumProc_in_Range            0.033260\n",
       "8                  ClmsPerPatient_in            0.029042\n",
       "9                   NumDiag_in_Range            0.022861\n",
       "10                     AgeRange_inpt            0.022254\n",
       "12                       PctDiabFrac            0.019700\n",
       "17                     AgeRange_otpt            0.018941\n",
       "14  InscClaimAmtReimbursed_out_Range            0.016910\n",
       "18         InscClaimAmtReimbursed_in            0.016868\n",
       "13              NumChronics_in_Range            0.015928\n",
       "15                ClmsPerPatient_out            0.015854\n",
       "16                         patDegMax            0.011160\n",
       "11                     oncology_inpt            0.009314\n",
       "51                    emergency_inpt            0.008924"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Red_Feature_Imp_Ave = rndm_score_red_dict[653683][2][[0]]\n",
    "for key in rndm_score_red_dict.keys():\n",
    "    RF_Red_Feature_Imp_Ave = pd.merge(RF_Red_Feature_Imp_Ave,rndm_score_red_dict[key][2], on=0)\n",
    "RF_Red_Feature_Imp_Ave['RF_Feature_Imp_Ave']=RF_Red_Feature_Imp_Ave.mean(axis=1)\n",
    "RF_Red_Feature_Imp_Ave = RF_Red_Feature_Imp_Ave.sort_values(by='RF_Feature_Imp_Ave', ascending=False)\n",
    "RF_Red_Feature_Imp_Ave = RF_Red_Feature_Imp_Ave.drop(columns=['1_x','1_y','1_x','1_y','1_y','1_y'])\n",
    "RF_Red_Feature_Imp_Ave.to_csv('RF_Red_Feature_Imp_Ave.csv')\n",
    "RF_Red_Feature_Imp_Ave.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced.to_csv('rf_reduced_feature_set')\n",
    "y_train.to_csv('rf_reduced_label_set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we attempt to develop a cost model to quantify the relative performance of each model. We read in the total claims data since we have decided to measure the dollar amount of claims of the fraudulent providers and the amount of that money that this model has identified as reimbursed to fraudulent providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/doug/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (10,13,14,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/combinedData.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum the money reimbursed to all providers, to be able to quantify the amount of money reimbursed to fraudulent providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>TotalClaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>104640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51003</td>\n",
       "      <td>605670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51004</td>\n",
       "      <td>52170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>280910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51007</td>\n",
       "      <td>33710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>PRV57759</td>\n",
       "      <td>10640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>PRV57760</td>\n",
       "      <td>4770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>PRV57761</td>\n",
       "      <td>18470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>PRV57762</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>43610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5410 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Provider  TotalClaim\n",
       "0     PRV51001      104640\n",
       "1     PRV51003      605670\n",
       "2     PRV51004       52170\n",
       "3     PRV51005      280910\n",
       "4     PRV51007       33710\n",
       "...        ...         ...\n",
       "5405  PRV57759       10640\n",
       "5406  PRV57760        4770\n",
       "5407  PRV57761       18470\n",
       "5408  PRV57762        1900\n",
       "5409  PRV57763       43610\n",
       "\n",
       "[5410 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Set']=='Train']\n",
    "data1 = data.groupby('Provider').agg('sum')['InscClaimAmtReimbursed'].reset_index()\n",
    "data1.columns=['Provider','TotalClaim']\n",
    "data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Provider', 'total_claim'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider_claim_test.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model presented is slightly different from this one, but essentially we attempt to acknowledge a cost associated with all invetigations, and impose an extra cost for false positive identifications of innocent providers as fraudulent.  We attempted to maximize the amount of money identified as from fraudulent providers, while also trying to maximize the ratio of the recovered money to the amount spent to get that money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[913  64]\n",
      " [ 24  81]]\n",
      "total claims for test set are $106,047,820\n",
      "total fraudulent claims are 51 % of total claims\n",
      "total investigation cost at 100K per 13 % of total claims\n",
      "total legal costs for false positives at 100K per are 6 % of total claims\n",
      "total recovered claims are 48 % of total claims\n",
      "total net benefit of model as Pct of total claims is 29 % of total claims\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame({'actual':y_test,'predict':randomForest.predict(X_test_reduced),'total_claim': provider_claim_test['total_claim']})\n",
    "print(confusion_matrix(y_test, randomForest.predict(X_test_reduced)))\n",
    "\n",
    "totalclaims = np.sum(a['total_claim'])\n",
    "totaldefrauded=100*np.sum(a[a['actual']==1]['total_claim'])/totalclaims\n",
    "\n",
    "print('total claims for test set are ${:,.0f}'.format(totalclaims))\n",
    "\n",
    "print('total fraudulent claims are %i' %totaldefrauded,'% of total claims')\n",
    "\n",
    "totalcost=100*np.sum(a[a['predict']==1]['predict'])*100000/totalclaims\n",
    "print('total investigation cost at 100K per %i' %totalcost,'% of total claims')\n",
    "\n",
    "totalfalsepos=100*np.sum(a[(a['predict']==1) & a['actual']==0]['predict'])*100000/totalclaims\n",
    "print('total legal costs for false positives at 100K per are %i' %totalfalsepos,'% of total claims')\n",
    "\n",
    "totalrecovered=100*np.sum(a[(a['predict']==1) & a['actual']==1]['total_claim'])/totalclaims\n",
    "print('total recovered claims are %i' %totalrecovered,'% of total claims')\n",
    "print('total net benefit of model as Pct of total claims is %i' %(totalrecovered-(totalcost+totalfalsepos)),'% of total claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082, 94)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Feature_Imp_Ave.to_csv('rf_feature_importance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
